{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_KRE1yZ0fX7"
      },
      "source": [
        " # **Progetto ICON**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzQ3RRaQohhj"
      },
      "source": [
        "# **Habitable exoplanets classification**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ9YXEWZpVVr"
      },
      "source": [
        "Descrizione del progetto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCTV5HarpiuZ"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import imp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, SMOTENC\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Machine Learning Algorithms\n",
        "#import xgboost as xgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, IsolationForest,\n",
        "                              RandomForestRegressor, AdaBoostClassifier, VotingClassifier, ExtraTreesClassifier)\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "\n",
        "# Performance metrics\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score, make_scorer, balanced_accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xgwSpaQpFKm"
      },
      "source": [
        "## **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "22zsnmYcpLR0",
        "outputId": "4a61848e-1be3-4da8-e488-d3449206d078"
      },
      "outputs": [],
      "source": [
        "planets = pd.read_csv(\"../PHL-EC.csv\")\n",
        "planets.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8VYqdf_qpyA"
      },
      "source": [
        "## **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD_h3Y8arVqz"
      },
      "source": [
        "Elimino le tipologie di pianeti per le quali abbiamo pochi esempi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx0Q7OFEqjIs",
        "outputId": "e1a70787-e566-488c-d14e-e7cf74a9ee6f"
      },
      "outputs": [],
      "source": [
        "target_count = planets['P. Habitable Class'].value_counts()\n",
        "target_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5en88T1arNgq"
      },
      "outputs": [],
      "source": [
        "indexNames = planets[planets['P. Habitable Class'] == 'thermoplanet'].index\n",
        "planets.drop(indexNames, inplace= True)\n",
        "\n",
        "\n",
        "indexNames = planets[planets['P. Habitable Class'] == 'hypopsychroplanet'].index\n",
        "planets.drop(indexNames, inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dyDoh8XrQkc",
        "outputId": "f116af86-6f6a-4141-dd71-68a672607431"
      },
      "outputs": [],
      "source": [
        "target_count = planets['P. Habitable Class'].value_counts()\n",
        "target_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVBaW-GsLA-G"
      },
      "outputs": [],
      "source": [
        "planets.reset_index(inplace = True, drop= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxPl-fkrrnti"
      },
      "source": [
        "Rimuovo alcune feauture segiendo alcune tecniche di feauture selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S30xuBmIrnOT"
      },
      "outputs": [],
      "source": [
        "#count = valori nulli in una colonna specifica(in una feature)\n",
        "#lenplanet(planet) = numero di righe totali(tot pianeti)\n",
        "#count/len(planet) = ci dice in percentuale quanti valori ci saranno in quella colonna\n",
        "\n",
        "def remove_missing(feauture):\n",
        "    count = len(planets[planets[feauture].isnull()])\n",
        "    if count/len(planets) > 0.2:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "missing_values = [x for x in planets.columns if remove_missing(x)]\n",
        "planets = planets.drop(missing_values, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHAuO4Ner-3e"
      },
      "outputs": [],
      "source": [
        "cols_to_drop = ['S. Constellation', 'S. Type', 'P. Int ESI', \n",
        "                'P. Surf ESI', 'P. Disc. Method', 'P. Disc. Year','P. Hab Moon', 'P. SFlux Min (EU)', 'P. SFlux Max (EU)',\n",
        "                'P. Teq Min (K)','P. Teq Max (K)','P. SFlux Mean (EU)','S. Name']\n",
        "\n",
        "planets = planets.drop(cols_to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqe5tUP4sGKO"
      },
      "source": [
        "Voglio rimuovere anche in base alla correlazione con l'attributo habitability class ma per usare la correlazione devo: \n",
        "\n",
        "*    riempire il dataset con i dati mancati\n",
        "*    traformare prima la feature habitable class (categorica) in feauture numerica\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGlTLGpYs3GS"
      },
      "source": [
        "riempio tramite l'inputer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUBRZTHo2ZUS",
        "outputId": "68a4d5c3-65b9-43a0-ee59-61c0569c6e02"
      },
      "outputs": [],
      "source": [
        "planets.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6fSqIac2KAE"
      },
      "outputs": [],
      "source": [
        "numeric_values = planets[planets._get_numeric_data().columns]\n",
        "\n",
        "\n",
        "imputer = SimpleImputer(missing_values = np.NaN, strategy = 'mean') #di default strategy ='mean'\n",
        "numeric_values = pd.DataFrame(imputer.fit_transform(numeric_values), columns=numeric_values.columns)\n",
        "numeric_values.to_csv('Imputed Data.csv', index='rowid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZVB5mLHtBve"
      },
      "outputs": [],
      "source": [
        "imputed_numerics = pd.read_csv('Imputed Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtEz0Jt5-Fqo"
      },
      "outputs": [],
      "source": [
        "for i in planets.columns:\n",
        "    if i not in imputed_numerics.columns:\n",
        "        pass\n",
        "    else:\n",
        "        planets[i] = imputed_numerics[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "catCols = [col for col in planets.columns if planets[col].dtype==\"O\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "simp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "planets[catCols] = simp.fit_transform(planets[catCols])\n",
        "planets.dropna(how='any', axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "planets.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7uqRS77u1K4"
      },
      "source": [
        "trasformo la feauture categorica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXO1p8SSu4Qj"
      },
      "source": [
        "#Convert string values of origin column to numerical values\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "label_encoder.fit(planets['P. Habitable Class'])\n",
        "\n",
        "# finding the unique classes\n",
        "print(list(label_encoder.classes_))\n",
        "print()\n",
        "\n",
        "# values after transforming the categorical column.\n",
        "print(label_encoder.transform(planets['P. Habitable Class']))\n",
        "\n",
        "planets['P. Habitable Class'] = label_encoder.transform(planets['P. Habitable Class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjYqzqR-x8XS"
      },
      "source": [
        "cor = planets.corr('spearman')\n",
        "cor.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGIzdA1RyBUY"
      },
      "source": [
        "sns.heatmap(cor, annot = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8G6IdhAyMQK"
      },
      "source": [
        "threshold = 0\n",
        "cor_h = cor['P. Habitable Class'].sort_values(ascending=False)\n",
        "result = cor_h.tail(20)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_SuTfaozG65"
      },
      "source": [
        "Possiamo notare come il dataset sia molto sblianciato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dp2x4iMzWrz",
        "outputId": "fc619c9f-1c5d-41c4-b864-9d1e77097f3e"
      },
      "outputs": [],
      "source": [
        "target_count = planets['P. Habitable Class'].value_counts()\n",
        "target_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54uEYwbFzYYr",
        "outputId": "b8427dda-56fd-4113-f878-27ccd7d03882"
      },
      "outputs": [],
      "source": [
        "target_count = planets['P. Habitable Class'].value_counts()\n",
        "print(f'non-habitable: {target_count[0]}')\n",
        "print(f'mesoplanet: {target_count[1]}')\n",
        "print(f'psychroplanet : {target_count[2]}')\n",
        "print(f'Percentage of Majority Class: {round(target_count[0] / sum(target_count), 4)*100}')\n",
        "print(f'Percentage of Minority Class: {round(target_count[1] / sum(target_count), 4)*100}')\n",
        "print(f'Percentage of Minority Class: {round(target_count[2] / sum(target_count), 4)*100}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8Q-4b0yUdTc"
      },
      "source": [
        "Divido il dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "X = Predictor features\n",
        "y = target feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "planets_c = planets.copy()\n",
        "planets_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X = planets_c.loc[ :, planets.columns != 'P. Habitable Class']\n",
        "y = planets.iloc[:, 5]\n",
        "\n",
        "X = X.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ora definiamo una pipeline per settare l'oversampling usando SMOTE sui dati di training , ad ogni cross-validation evaluation process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "steps = [('over', SMOTE()), ('model', LogisticRegression())] #mettiamo il modello di classificazione\n",
        "pipeline = Pipeline(steps=steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ora usiamo stratified k-fold cross-validation per dividere il nostro dat in più folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=3,random_state=None,shuffle=False)\n",
        "\n",
        "for train_index,test_index in skf.split(X,y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "    \n",
        "    print(\"Train X :\", X_train, \"|\", \"Test X :\", X_test)\n",
        "    print(\"Train y :\", y_train, \"|\", \"Test y :\", y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJYE4rhyZMHs"
      },
      "source": [
        "effettuo oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "catIndex=[0, 1, 2, 3, 4, 5]\n",
        "catIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict = {'psychroplanet': 2000,\n",
        "    'mesoplanet': 2000}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#facciamo l'oversampling\n",
        "smote = SMOTENC(random_state = 11, sampling_strategy = dict, categorical_features = catIndex)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = pd.DataFrame(y_train, columns = ['P. Habitable Class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il dataset non è più sbilanciato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_count = Y['P. Habitable Class'].value_counts()\n",
        "print(f'non-habitable: {target_count[0]}')\n",
        "print(f'mesoplanet: {target_count[1]}')\n",
        "print(f'psychroplanet : {target_count[2]}')\n",
        "print(f'Percentage of Majority Class: {round(target_count[0] / sum(target_count), 4)*100}')\n",
        "print(f'Percentage of Minority Class: {round(target_count[1] / sum(target_count), 4)*100}')\n",
        "print(f'Percentage of Minority Class: {round(target_count[2] / sum(target_count), 4)*100}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "prima di poter effettuare la classificazione devo trasformare le feature categoriche in numeriche;\n",
        "trasformo la feature target tramite l'encoder e quelle normali tramite altri metodi, quali????"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pre =model.predic(X_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "717b56f8e080388875483ba11ddc0d89304d34693b8198efc15e804199a980e5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
